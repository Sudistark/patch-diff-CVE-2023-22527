package com.hazelcast.map.impl.query;

import com.hazelcast.aggregation.Aggregator;
import com.hazelcast.query.impl.QueryableEntry;
import com.hazelcast.query.impl.predicates.PredicateUtils;
import com.hazelcast.spi.serialization.SerializationService;
import com.hazelcast.util.FutureUtil;
import com.hazelcast.util.executor.ManagedExecutorService;
import java.util.ArrayList;
import java.util.Collection;
import java.util.concurrent.Future;
import java.util.concurrent.TimeUnit;

public class ParallelAccumulationExecutor implements AccumulationExecutor {
  private static final int THREAD_SPLIT_COUNT = 8;
  
  private final ManagedExecutorService executor;
  
  private final SerializationService serializationService;
  
  private final int callTimeoutInMillis;
  
  public ParallelAccumulationExecutor(ManagedExecutorService executor, SerializationService serializationService, int callTimeoutInMillis) {
    this.executor = executor;
    this.serializationService = serializationService;
    this.callTimeoutInMillis = callTimeoutInMillis;
  }
  
  public AggregationResult execute(Aggregator aggregator, Collection<QueryableEntry> entries, Collection<Integer> partitionIds) {
    Collection<Aggregator> chunkAggregators = accumulateParallel(aggregator, entries);
    resultAggregator = clone(aggregator);
    try {
      for (Aggregator chunkAggregator : chunkAggregators)
        resultAggregator.combine(chunkAggregator); 
    } finally {
      resultAggregator.onCombinationFinished();
    } 
    AggregationResult result = new AggregationResult(resultAggregator, this.serializationService);
    result.setPartitionIds(partitionIds);
    return result;
  }
  
  protected Collection<Aggregator> accumulateParallel(Aggregator aggregator, Collection<QueryableEntry> entries) {
    Collection<Future<Aggregator>> futures = new ArrayList<Future<Aggregator>>();
    Collection[] chunks = split(entries, 8);
    if (chunks == null) {
      AccumulatePartitionCallable task = new AccumulatePartitionCallable(clone(aggregator), entries, null);
      futures.add(this.executor.submit(task));
    } else {
      for (Collection<QueryableEntry> chunk : chunks) {
        AccumulatePartitionCallable task = new AccumulatePartitionCallable(clone(aggregator), chunk, null);
        futures.add(this.executor.submit(task));
      } 
    } 
    return FutureUtil.returnWithDeadline(futures, this.callTimeoutInMillis, TimeUnit.MILLISECONDS, FutureUtil.RETHROW_EVERYTHING);
  }
  
  private Collection<QueryableEntry>[] split(Collection<QueryableEntry> entries, int chunkCount) {
    int estimatedSize = PredicateUtils.estimatedSizeOf(entries);
    if (estimatedSize < chunkCount * 2)
      return null; 
    int counter = 0;
    Collection[] entriesSplit = new Collection[chunkCount];
    int entriesPerChunk = estimatedSize / chunkCount;
    for (int i = 0; i < chunkCount; i++)
      entriesSplit[i] = new ArrayList(entriesPerChunk); 
    for (QueryableEntry entry : entries)
      entriesSplit[counter++ % 8].add(entry); 
    return entriesSplit;
  }
  
  private Aggregator clone(Aggregator aggregator) { return (Aggregator)this.serializationService.toObject(this.serializationService.toData(aggregator)); }
}
