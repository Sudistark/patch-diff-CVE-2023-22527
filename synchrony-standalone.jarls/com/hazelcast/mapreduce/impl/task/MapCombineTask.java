package com.hazelcast.mapreduce.impl.task;

import com.hazelcast.internal.serialization.InternalSerializationService;
import com.hazelcast.mapreduce.JobPartitionState;
import com.hazelcast.mapreduce.KeyValueSource;
import com.hazelcast.mapreduce.LifecycleMapper;
import com.hazelcast.mapreduce.Mapper;
import com.hazelcast.mapreduce.impl.MapReduceService;
import com.hazelcast.mapreduce.impl.MapReduceUtil;
import com.hazelcast.mapreduce.impl.notification.IntermediateChunkNotification;
import com.hazelcast.mapreduce.impl.notification.LastChunkNotification;
import com.hazelcast.mapreduce.impl.operation.KeysAssignmentOperation;
import com.hazelcast.mapreduce.impl.operation.KeysAssignmentResult;
import com.hazelcast.mapreduce.impl.operation.PostPonePartitionProcessing;
import com.hazelcast.mapreduce.impl.operation.RequestPartitionProcessed;
import com.hazelcast.mapreduce.impl.operation.RequestPartitionReducing;
import com.hazelcast.mapreduce.impl.operation.RequestPartitionResult;
import com.hazelcast.nio.Address;
import com.hazelcast.spi.NodeEngine;
import com.hazelcast.spi.partition.IPartitionService;
import com.hazelcast.spi.serialization.SerializationService;
import com.hazelcast.util.ExceptionUtil;
import com.hazelcast.util.MapUtil;
import com.hazelcast.util.SetUtil;
import java.util.Collection;
import java.util.Collections;
import java.util.HashMap;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.atomic.AtomicBoolean;

public class MapCombineTask<KeyIn, ValueIn, KeyOut, ValueOut, Chunk> extends Object {
  private final AtomicBoolean cancelled;
  
  private final Mapper<KeyIn, ValueIn, KeyOut, ValueOut> mapper;
  
  private final MappingPhase<KeyIn, ValueIn, KeyOut, ValueOut> mappingPhase;
  
  private final KeyValueSource<KeyIn, ValueIn> keyValueSource;
  
  private final MapReduceService mapReduceService;
  
  private final IPartitionService partitionService;
  
  private final SerializationService serializationService;
  
  private final JobSupervisor supervisor;
  
  private final NodeEngine nodeEngine;
  
  private final String name;
  
  private final String jobId;
  
  private final int chunkSize;
  
  public MapCombineTask(JobTaskConfiguration configuration, JobSupervisor supervisor, MappingPhase<KeyIn, ValueIn, KeyOut, ValueOut> mappingPhase) {
    this.cancelled = new AtomicBoolean();
    this.mappingPhase = mappingPhase;
    this.supervisor = supervisor;
    this.mapper = configuration.getMapper();
    this.name = configuration.getName();
    this.jobId = configuration.getJobId();
    this.chunkSize = configuration.getChunkSize();
    this.nodeEngine = configuration.getNodeEngine();
    this.partitionService = this.nodeEngine.getPartitionService();
    this.serializationService = this.nodeEngine.getSerializationService();
    this.mapReduceService = supervisor.getMapReduceService();
    this.keyValueSource = configuration.getKeyValueSource();
  }
  
  public String getName() { return this.name; }
  
  public String getJobId() { return this.jobId; }
  
  public int getChunkSize() { return this.chunkSize; }
  
  public void cancel() {
    this.cancelled.set(true);
    this.mappingPhase.cancel();
  }
  
  public void process() {
    ExecutorService es = this.mapReduceService.getExecutorService(this.name);
    if (this.keyValueSource instanceof com.hazelcast.mapreduce.PartitionIdAware) {
      es.submit(new PartitionBasedProcessor(this, null));
    } else {
      es.submit(new NonPartitionBasedProcessor(this, null));
    } 
  }
  
  public final void processMapping(int partitionId, DefaultContext<KeyOut, ValueOut> context, KeyValueSource<KeyIn, ValueIn> keyValueSource, boolean partitionProcessor) throws Exception {
    context.setPartitionId(partitionId);
    context.setSerializationService((InternalSerializationService)this.serializationService);
    if (this.mapper instanceof LifecycleMapper)
      ((LifecycleMapper)this.mapper).initialize(context); 
    int keyPreSelectorId = partitionProcessor ? partitionId : -1;
    if (this.mappingPhase.processingPartitionNecessary(keyPreSelectorId, this.partitionService))
      this.mappingPhase.executeMappingPhase(keyValueSource, this.mapper, context); 
    if (this.mapper instanceof LifecycleMapper)
      ((LifecycleMapper)this.mapper).finalized(context); 
  }
  
  void onEmit(DefaultContext<KeyOut, ValueOut> context, int partitionId) {
    if (this.supervisor.getConfiguration().getReducerFactory() != null && 
      context.getCollected() == this.chunkSize) {
      Map<KeyOut, Chunk> chunkMap = context.requestChunk();
      Map<Address, Map<KeyOut, Chunk>> mapping = mapResultToMember(this.supervisor, chunkMap);
      this.supervisor.registerReducerEventInterests(partitionId, mapping.keySet());
      for (Map.Entry<Address, Map<KeyOut, Chunk>> entry : mapping.entrySet())
        this.mapReduceService.sendNotification((Address)entry.getKey(), new IntermediateChunkNotification((Address)entry
              .getKey(), this.name, this.jobId, (Map)entry.getValue(), partitionId)); 
    } 
  }
  
  public static <K, V> Map<Address, Map<K, V>> mapResultToMember(JobSupervisor supervisor, Map<K, V> result) {
    Set<Object> unassignedKeys = SetUtil.createHashSet(result.size());
    for (Map.Entry<K, V> entry : result.entrySet()) {
      Address address = supervisor.getReducerAddressByKey(entry.getKey());
      if (address == null)
        unassignedKeys.add(entry.getKey()); 
    } 
    if (unassignedKeys.size() > 0)
      requestAssignment(unassignedKeys, supervisor); 
    Map<Address, Map<K, V>> mapping = MapUtil.createHashMap(result.size());
    for (Map.Entry<K, V> entry : result.entrySet()) {
      Address address = supervisor.getReducerAddressByKey(entry.getKey());
      if (address != null) {
        Map<K, V> data = (Map)mapping.get(address);
        if (data == null) {
          data = new HashMap<K, V>();
          mapping.put(address, data);
        } 
        data.put(entry.getKey(), entry.getValue());
      } 
    } 
    return mapping;
  }
  
  private static void requestAssignment(Set<Object> keys, JobSupervisor supervisor) {
    try {
      MapReduceService mapReduceService = supervisor.getMapReduceService();
      String name = supervisor.getConfiguration().getName();
      String jobId = supervisor.getConfiguration().getJobId();
      KeysAssignmentResult assignmentResult = (KeysAssignmentResult)mapReduceService.processRequest(supervisor.getJobOwner(), new KeysAssignmentOperation(name, jobId, keys));
      if (assignmentResult.getResultState() == RequestPartitionResult.ResultState.SUCCESSFUL) {
        Map<Object, Address> assignment = assignmentResult.getAssignment();
        for (Map.Entry<Object, Address> entry : assignment.entrySet()) {
          if (!supervisor.assignKeyReducerAddress(entry.getKey(), (Address)entry.getValue()))
            throw new IllegalStateException("Key reducer assignment in illegal state"); 
        } 
      } 
    } catch (Exception e) {
      throw new RuntimeException(e);
    } 
  }
  
  private void finalizeMapping(int partitionId, DefaultContext<KeyOut, ValueOut> context) throws Exception {
    RequestPartitionResult result = (RequestPartitionResult)this.mapReduceService.processRequest(this.supervisor.getJobOwner(), new RequestPartitionReducing(this.name, this.jobId, partitionId));
    if (result.getResultState() == RequestPartitionResult.ResultState.SUCCESSFUL)
      if (this.supervisor.getConfiguration().getReducerFactory() != null) {
        Map<KeyOut, Chunk> chunkMap = context.requestChunk();
        if (chunkMap.size() > 0) {
          sendLastChunkToAssignedReducers(partitionId, chunkMap);
        } else {
          finalizeProcessing(partitionId);
        } 
      }  
  }
  
  private void finalizeProcessing(int partitionId) throws Exception {
    RequestPartitionResult result = (RequestPartitionResult)this.mapReduceService.processRequest(this.supervisor.getJobOwner(), new RequestPartitionProcessed(this.name, this.jobId, partitionId, JobPartitionState.State.REDUCING));
    if (result.getResultState() != RequestPartitionResult.ResultState.SUCCESSFUL)
      throw new RuntimeException("Could not finalize processing for partitionId " + partitionId); 
  }
  
  private void sendLastChunkToAssignedReducers(int partitionId, Map<KeyOut, Chunk> chunkMap) {
    Address sender = this.mapReduceService.getLocalAddress();
    Map<Address, Map<KeyOut, Chunk>> mapping = mapResultToMember(this.supervisor, chunkMap);
    this.supervisor.registerReducerEventInterests(partitionId, mapping.keySet());
    for (Map.Entry<Address, Map<KeyOut, Chunk>> entry : mapping.entrySet()) {
      Address receiver = (Address)entry.getKey();
      Map<KeyOut, Chunk> chunk = (Map)entry.getValue();
      this.mapReduceService
        .sendNotification(receiver, new LastChunkNotification(receiver, this.name, this.jobId, sender, partitionId, chunk));
    } 
    Set<Address> addresses = mapping.keySet();
    Collection<Address> reducerInterests = this.supervisor.getReducerEventInterests(partitionId);
    if (reducerInterests != null)
      for (Address address : reducerInterests) {
        if (!addresses.contains(address))
          this.mapReduceService.sendNotification(address, new LastChunkNotification(address, this.name, this.jobId, sender, partitionId, 
                Collections.emptyMap())); 
      }  
  }
  
  private void postponePartitionProcessing(int partitionId) throws Exception {
    RequestPartitionResult result = (RequestPartitionResult)this.mapReduceService.processRequest(this.supervisor.getJobOwner(), new PostPonePartitionProcessing(this.name, this.jobId, partitionId));
    if (result.getResultState() != RequestPartitionResult.ResultState.SUCCESSFUL)
      throw new RuntimeException("Could not postpone processing for partitionId " + partitionId + " -> " + result
          .getResultState()); 
  }
  
  private void handleProcessorThrowable(Throwable t) {
    MapReduceUtil.notifyRemoteException(this.supervisor, t);
    if (t instanceof Error)
      ExceptionUtil.sneakyThrow(t); 
  }
  
  private void processPartitionMapping(KeyValueSource<KeyIn, ValueIn> delegate, int partitionId, boolean partitionProcessor) throws Exception {
    delegate.reset();
    if (delegate.open(this.nodeEngine)) {
      DefaultContext<KeyOut, ValueOut> context = this.supervisor.getOrCreateContext(this);
      processMapping(partitionId, context, delegate, partitionProcessor);
      delegate.close();
      finalizeMapping(partitionId, context);
    } else {
      postponePartitionProcessing(partitionId);
    } 
  }
}
