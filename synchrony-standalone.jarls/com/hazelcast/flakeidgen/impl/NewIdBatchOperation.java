package com.hazelcast.flakeidgen.impl;

import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.IdentifiedDataSerializable;
import com.hazelcast.spi.Operation;
import java.io.IOException;
import java.util.concurrent.TimeUnit;

class NewIdBatchOperation extends Operation implements IdentifiedDataSerializable {
  private String flakeIdGenName;
  
  private int batchSize;
  
  NewIdBatchOperation() {}
  
  NewIdBatchOperation(String genName, int batchSize) {
    this.flakeIdGenName = genName;
    this.batchSize = batchSize;
  }
  
  public void run() {
    FlakeIdGeneratorProxy proxy = (FlakeIdGeneratorProxy)getNodeEngine().getProxyService().getDistributedObject(getServiceName(), this.flakeIdGenName);
    FlakeIdGeneratorProxy.IdBatchAndWaitTime result = proxy.newIdBaseLocal(this.batchSize);
    if (result.waitTimeMillis == 0L) {
      sendResponse(Long.valueOf(result.idBatch.base()));
    } else {
      getNodeEngine().getExecutionService().schedule(new Object(this, result), result.waitTimeMillis, TimeUnit.MILLISECONDS);
    } 
  }
  
  public boolean returnsResponse() { return false; }
  
  public String getServiceName() { return "hz:impl:flakeIdGeneratorService"; }
  
  public int getFactoryId() { return FlakeIdGeneratorDataSerializerHook.F_ID; }
  
  public int getId() { return 0; }
  
  protected void readInternal(ObjectDataInput in) throws IOException {
    this.flakeIdGenName = in.readUTF();
    this.batchSize = in.readInt();
  }
  
  protected void writeInternal(ObjectDataOutput out) throws IOException {
    out.writeUTF(this.flakeIdGenName);
    out.writeInt(this.batchSize);
  }
  
  protected void toString(StringBuilder sb) {
    super.toString(sb);
    sb.append(", flakeIdGenName=").append(this.flakeIdGenName);
    sb.append(", batchSize=").append(this.batchSize);
  }
}
