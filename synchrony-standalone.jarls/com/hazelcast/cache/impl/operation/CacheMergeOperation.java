package com.hazelcast.cache.impl.operation;

import com.hazelcast.cache.impl.record.CacheRecord;
import com.hazelcast.instance.MemberImpl;
import com.hazelcast.internal.cluster.Versions;
import com.hazelcast.nio.Address;
import com.hazelcast.nio.ObjectDataInput;
import com.hazelcast.nio.ObjectDataOutput;
import com.hazelcast.nio.serialization.Data;
import com.hazelcast.spi.BackupAwareOperation;
import com.hazelcast.spi.Operation;
import com.hazelcast.spi.impl.operationservice.TargetAware;
import com.hazelcast.spi.merge.SplitBrainMergePolicy;
import com.hazelcast.spi.merge.SplitBrainMergeTypes;
import com.hazelcast.util.MapUtil;
import com.hazelcast.version.Version;
import com.hazelcast.wan.impl.CallerProvenance;
import java.io.IOException;
import java.util.ArrayList;
import java.util.List;
import java.util.Map;

public class CacheMergeOperation extends CacheOperation implements BackupAwareOperation, TargetAware {
  private List<SplitBrainMergeTypes.CacheMergeTypes> mergingEntries;
  
  private SplitBrainMergePolicy<Data, SplitBrainMergeTypes.CacheMergeTypes> mergePolicy;
  
  private boolean hasBackups;
  
  private Map<Data, CacheRecord> backupRecords;
  
  private Address target;
  
  public CacheMergeOperation() {}
  
  public CacheMergeOperation(String name, List<SplitBrainMergeTypes.CacheMergeTypes> mergingEntries, SplitBrainMergePolicy<Data, SplitBrainMergeTypes.CacheMergeTypes> mergePolicy) {
    super(name);
    this.mergingEntries = mergingEntries;
    this.mergePolicy = mergePolicy;
  }
  
  protected void beforeRunInternal() {
    this.hasBackups = (getSyncBackupCount() + getAsyncBackupCount() > 0);
    if (this.hasBackups)
      this.backupRecords = MapUtil.createHashMap(this.mergingEntries.size()); 
  }
  
  public void run() {
    for (SplitBrainMergeTypes.CacheMergeTypes mergingEntry : this.mergingEntries)
      merge(mergingEntry); 
  }
  
  private void merge(SplitBrainMergeTypes.CacheMergeTypes mergingEntry) {
    Data dataKey = (Data)mergingEntry.getKey();
    CacheRecord backupRecord = this.recordStore.merge(mergingEntry, this.mergePolicy, CallerProvenance.NOT_WAN);
    if (backupRecord != null)
      this.backupRecords.put(dataKey, backupRecord); 
    if (this.recordStore.isWanReplicationEnabled())
      if (backupRecord != null) {
        publishWanUpdate(dataKey, backupRecord);
      } else {
        publishWanRemove(dataKey);
      }  
  }
  
  public Object getResponse() { return Boolean.valueOf(!this.backupRecords.isEmpty()); }
  
  public boolean shouldBackup() { return (this.hasBackups && !this.backupRecords.isEmpty()); }
  
  public Operation getBackupOperation() { return new CachePutAllBackupOperation(this.name, this.backupRecords); }
  
  public void setTarget(Address address) { this.target = address; }
  
  protected boolean requiresExplicitServiceName() {
    MemberImpl memberImpl = getNodeEngine().getClusterService().getMember(this.target);
    if (memberImpl == null)
      return false; 
    Version memberVersion = memberImpl.getVersion().asVersion();
    return memberVersion.isLessThan(Versions.V3_11);
  }
  
  protected void writeInternal(ObjectDataOutput out) throws IOException {
    super.writeInternal(out);
    out.writeInt(this.mergingEntries.size());
    for (SplitBrainMergeTypes.CacheMergeTypes mergingEntry : this.mergingEntries)
      out.writeObject(mergingEntry); 
    out.writeObject(this.mergePolicy);
  }
  
  protected void readInternal(ObjectDataInput in) throws IOException {
    super.readInternal(in);
    int size = in.readInt();
    this.mergingEntries = new ArrayList(size);
    for (int i = 0; i < size; i++) {
      SplitBrainMergeTypes.CacheMergeTypes mergingEntry = (SplitBrainMergeTypes.CacheMergeTypes)in.readObject();
      this.mergingEntries.add(mergingEntry);
    } 
    this.mergePolicy = (SplitBrainMergePolicy)in.readObject();
  }
  
  public int getId() { return 65; }
}
